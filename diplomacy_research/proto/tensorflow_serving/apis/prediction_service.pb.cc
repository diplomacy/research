// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/prediction_service.proto

#include "tensorflow_serving/apis/prediction_service.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// This is a temporary google only hack
#ifdef GOOGLE_PROTOBUF_ENFORCE_UNIQUENESS
#include "third_party/protobuf/version.h"
#endif
// @@protoc_insertion_point(includes)

namespace tensorflow {
namespace serving {
}  // namespace serving
}  // namespace tensorflow
namespace protobuf_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto {
void InitDefaults() {
}

const ::google::protobuf::uint32 TableStruct::offsets[1] = {};
static const ::google::protobuf::internal::MigrationSchema* schemas = NULL;
static const ::google::protobuf::Message* const* file_default_instances = NULL;

void protobuf_AssignDescriptors() {
  AddDescriptors();
  AssignDescriptors(
      "tensorflow_serving/apis/prediction_service.proto", schemas, file_default_instances, TableStruct::offsets,
      NULL, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_PROTOBUF_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
}

void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
      "\n0tensorflow_serving/apis/prediction_ser"
      "vice.proto\022\022tensorflow.serving\032,tensorfl"
      "ow_serving/apis/classification.proto\0320te"
      "nsorflow_serving/apis/get_model_metadata"
      ".proto\032\'tensorflow_serving/apis/inferenc"
      "e.proto\032%tensorflow_serving/apis/predict"
      ".proto\032(tensorflow_serving/apis/regressi"
      "on.proto2\374\003\n\021PredictionService\022a\n\010Classi"
      "fy\022).tensorflow.serving.ClassificationRe"
      "quest\032*.tensorflow.serving.Classificatio"
      "nResponse\022X\n\007Regress\022%.tensorflow.servin"
      "g.RegressionRequest\032&.tensorflow.serving"
      ".RegressionResponse\022R\n\007Predict\022\".tensorf"
      "low.serving.PredictRequest\032#.tensorflow."
      "serving.PredictResponse\022g\n\016MultiInferenc"
      "e\022).tensorflow.serving.MultiInferenceReq"
      "uest\032*.tensorflow.serving.MultiInference"
      "Response\022m\n\020GetModelMetadata\022+.tensorflo"
      "w.serving.GetModelMetadataRequest\032,.tens"
      "orflow.serving.GetModelMetadataResponseB"
      "\003\370\001\001b\006proto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 812);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/apis/prediction_service.proto", &protobuf_RegisterTypes);
  ::protobuf_tensorflow_5fserving_2fapis_2fclassification_2eproto::AddDescriptors();
  ::protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fmetadata_2eproto::AddDescriptors();
  ::protobuf_tensorflow_5fserving_2fapis_2finference_2eproto::AddDescriptors();
  ::protobuf_tensorflow_5fserving_2fapis_2fpredict_2eproto::AddDescriptors();
  ::protobuf_tensorflow_5fserving_2fapis_2fregression_2eproto::AddDescriptors();
}

void AddDescriptors() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at dynamic initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;
}  // namespace protobuf_tensorflow_5fserving_2fapis_2fprediction_5fservice_2eproto
namespace tensorflow {
namespace serving {

// @@protoc_insertion_point(namespace_scope)
}  // namespace serving
}  // namespace tensorflow
namespace google {
namespace protobuf {
}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)
